{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvatore Depasquale and Brian Dilosa | ITS365 | Final Project \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = \"data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ([\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'attack',\n",
    "    'level'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(raw_data, header = None, names = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_value(value):\n",
    "    if value == 'normal':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "data['attack'] = data['attack'].apply(map_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = data.dtypes\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims = {}\n",
    "\n",
    "for col in data.columns:\n",
    "    if types[col] == 'object':\n",
    "        l_enc = LabelEncoder()\n",
    "        data[col] = l_enc.fit_transform(data[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        data.fillna(data[col].mean(), inplace = True)\n",
    "\n",
    "data.drop(columns=['level'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 0)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "test_ds = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size = 128, \n",
    "    shuffle = True, \n",
    "    num_workers = 1, \n",
    "    pin_memory = True,\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size = 25196, \n",
    "    num_workers = 1, \n",
    "    pin_memory = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.hidden_1 = nn.Linear(41, 40)\n",
    "        self.hidden_2 = nn.Linear(40, 40)\n",
    "        self.hidden_3 = nn.Linear(40, 40)\n",
    "        self.hidden_4 = nn.Linear(40, 20)\n",
    "        self.output_layer = nn.Linear(20, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden_1(x))\n",
    "        x = F.relu(self.hidden_2(x))\n",
    "        x = F.relu(self.hidden_3(x))\n",
    "        x = F.relu(self.hidden_4(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, lossFunction, opt):\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(\"cuda\"), target.to(\"cuda\")\n",
    "            opt.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = lossFunction(output, target)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 0.286006\n",
      "Epoch: 1 \tTraining Loss: 0.180307\n",
      "Epoch: 2 \tTraining Loss: 0.176721\n",
      "Epoch: 3 \tTraining Loss: 0.177424\n",
      "Epoch: 4 \tTraining Loss: 0.175076\n",
      "Epoch: 5 \tTraining Loss: 0.179087\n",
      "Epoch: 6 \tTraining Loss: 0.175513\n",
      "Epoch: 7 \tTraining Loss: 0.172842\n",
      "Epoch: 8 \tTraining Loss: 0.206537\n",
      "Epoch: 9 \tTraining Loss: 0.203310\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "train(epochs, model, lossFunction, opt)\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = Network()\n",
    "model_loaded.load_state_dict(torch.load(\"model.pt\"))\n",
    "model_loaded = model_loaded.to(\"cuda\")\n",
    "\n",
    "epochs_new = 1\n",
    "\n",
    "train(epochs_new, model_loaded, lossFunction, opt)\n",
    "\n",
    "torch.save(model_loaded.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, lossFunction):\n",
    "    class_correct = list(0. for i in range(41))\n",
    "    class_total = list(0. for i in range(41))\n",
    "    test_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        loss = lossFunction(output, target)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        _, pred = torch.max(output, 1)    \n",
    "        correct_tensor = pred.eq(target)\n",
    "        correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "        for i in range(len(data)):\n",
    "            label = target[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    test_loss = test_loss/len(test_loader.dataset)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    accuracy_0 = 100 * class_correct[0] / class_total[0]\n",
    "    accuracy_1 = 100 * class_correct[1] / class_total[1]\n",
    "    print('Test Accuracy of predicting that it is a normal packet: %2d%% (%2d/%2d)' % (\n",
    "        accuracy_0, np.sum(class_correct[0]), np.sum(class_total[0])))\n",
    "    print('Test Accuracy of predicting that is is a malicious packet: %2d%% (%2d/%2d)' % (\n",
    "        accuracy_1, np.sum(class_correct[1]), np.sum(class_total[1])))\n",
    "    \n",
    "    confmat = confusion_matrix(target, pred)\n",
    "\n",
    "    precision = precision_score(target, pred, average = 'weighted')\n",
    "\n",
    "    recall = recall_score(target, pred, average = 'weighted')\n",
    "\n",
    "    f1 = f1_score(target, pred, average = 'weighted')\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confmat, \"\\n\")\n",
    "\n",
    "    print(\"Precision score: \", precision, \"\\n\")\n",
    "    print(\"Recall score: \", recall, \"\\n\")\n",
    "    print(\"F1 score: \", f1, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.172381\n",
      "\n",
      "Test Accuracy of predicting that it is a normal packet: 99% (6679/6695)\n",
      "Test Accuracy of predicting that is is a malicious packet: 89% (5286/5903)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6679   16]\n",
      " [ 617 5286]] \n",
      "\n",
      "Precision score:  0.953644312052744 \n",
      "\n",
      "Recall score:  0.9497539291951104 \n",
      "\n",
      "F1 score:  0.9494856005257662 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_final = Network()\n",
    "model_final.load_state_dict(torch.load(\"model.pt\"))\n",
    "model_final = model_final.to(\"cpu\")\n",
    "\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "test(model_final, lossFunction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
